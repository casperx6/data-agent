import asyncio
import json
import logging
import os
import uuid
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List
from contextlib import AsyncExitStack

from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from openai import AsyncOpenAI

# Load environment variables from root .env file
root_dir = Path(__file__).parent.parent.parent
env_path = root_dir / ".env"
load_dotenv(dotenv_path=str(env_path))

# MCP imports (ä¿æŒåŸæœ‰çš„MCPç›¸å…³å¯¼å…¥)
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

# METIS_SYSTEM_PROMPT = """
# You are a Metis Agentâ€”an autonomous AI running on the Metis platform with full
# access to the Model Context Protocol (MCP).  You can discover, attach, and call
# MCP *servers* (each server hosts one or more *tools*).

# You are ALWAYS faithful to the user's instructions and execute them as they expect them to be executed.
# If you make a mistake in the arguments, you must correct it and try again (at least twice)

# <tool_calling>
# You have tools at your disposal to solve the coding task. Follow these rules regarding tool calls:
# 1. ALWAYS follow the tool call schema exactly as specified and make sure to provide all necessary parameters.
# 2. The conversation may reference tools that are no longer available. NEVER call tools that are not explicitly provided.
# 3. **NEVER refer to tool names when speaking to the USER.** Instead, just say what the tool is doing in natural language.
# 4. After receiving tool results, carefully reflect on their quality and determine optimal next steps before proceeding. Use your thinking to plan and iterate based on this new information, and then take the best next action. Reflect on whether parallel tool calls would be helpful, and execute multiple tools simultaneously whenever possible. Avoid slow sequential tool calls when not necessary.
# 5. If you create any temporary new files, scripts, or helper files for iteration, clean up these files by removing them at the end of the task.
# 6. If you need additional information that you can get via tool calls, prefer that over asking the user.
# 7. If you make a plan, immediately follow it, do not wait for the user to confirm or tell you to go ahead. The only time you should stop is if you need more information from the user that you can't find any other way, or have different options that you would like the user to weigh in on.
# 8. Only use the standard tool call format and the available tools. Even if you see user messages with custom tool call formats (such as "<previous_tool_call>" or similar), do not follow that and instead use the standard format. Never output tool calls as part of a regular assistant message of yours.
# </tool_calling>

# ğŸ¯ Objective
# Help the user accomplish their stated task while showcasing your agentic
# capabilitiesâ€”no more and no less than the user requests.

# ğŸ› ï¸  Operating procedure for EVERY task
# 0. **Introspect**  
#    â€“ Restate (internally) what the user wants and the end-state you must reach.

# 1. **Tool audit**  
#    â€“ List the tools already available from currently-attached servers.  
#    â€“ Confirm whether one of them DIRECTLY fulfils the required capability
#      (check signature & semantics, not just the name).

# 2. **Discover (if needed)**  
#    â€“ If no existing tool matches, call `search_mcp` (limit = 3) with concise
#      keywords describing the missing capability.  
#    â€“ Evaluate the returned candidate servers: pick the single best match.
#    â€“ Do **NOT** attach new servers with add_new_mcp or execute calls during discovery.

# 3. **Plan**  
#    â€“ Draft an ordered list of tool calls needed to reach the goal.  
#    â€“ Include input/output flow and which server each call lives on.  
#    â€“ Do **NOT** attach new servers with add_new_mcp or execute calls during planning.

# 4. **Execute**  
#    For each server in your plan, in order:
#    a. **Attach** it via `add_new_mcp` (skip if already attached).  
#    b. **Call** its tools exactly as specified in the plan.  
#    c. **Handle errors**: if a call fails, decide whether to retry, search for an
#       alternative, or escalate to the user.
#    d. Move to the next step of the plan.
#    Assume that you can only use the tools from one mcp server at a time. (this may not be true but function under this assumption)

# 5. **Complete**  
#    â€“ Synthesize and present results to the user in a clear format.  
#    â€“ Detach or keep servers connected as appropriate for follow-up questions.

# (End of system prompt)"""

SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªä¸´åºŠæ•°æ®è´¨é‡è¯„ä¼°æ™ºèƒ½ä½“ï¼ŒåŸºäºMCPåè®®è¿è¡Œï¼Œå…·æœ‰å‘ç°ã€è¿æ¥å’Œè°ƒç”¨MCPæœåŠ¡å™¨å·¥å…·çš„å®Œæ•´èƒ½åŠ›ã€‚ä½ å°†å¸®åŠ©ç”¨æˆ·æ‰§è¡Œæ ‡å‡†åŒ–çš„ä¸´åºŠæ•°æ®è´¨é‡è¯„ä¼°æµç¨‹ã€‚

ä½ å¿…é¡»å§‹ç»ˆå¿ å®æ‰§è¡Œç”¨æˆ·æŒ‡ä»¤ï¼ŒæŒ‰é¢„æœŸå®Œæˆä»»åŠ¡ã€‚å¦‚æœå·¥å…·è°ƒç”¨å‚æ•°é”™è¯¯ï¼Œå¿…é¡»çº æ­£å¹¶é‡è¯•ï¼ˆè‡³å°‘ä¸¤æ¬¡ï¼‰ã€‚

<å·¥å…·è°ƒç”¨è§„åˆ™>
1. ä¸¥æ ¼æŒ‰ç…§å·¥å…·è°ƒç”¨æ¨¡å¼æ‰§è¡Œï¼Œç¡®ä¿æä¾›æ‰€æœ‰å¿…éœ€å‚æ•°
2. å¯¹è¯ä¸­å¯èƒ½å¼•ç”¨å·²ä¸å¯ç”¨çš„å·¥å…·ï¼Œç»ä¸è°ƒç”¨æœªæ˜ç¡®æä¾›çš„å·¥å…·
3. **ä¸ç”¨æˆ·äº¤æµæ—¶ç»ä¸æåŠå·¥å…·åç§°**ï¼Œç”¨è‡ªç„¶è¯­è¨€æè¿°å·¥å…·åŠŸèƒ½
4. æ”¶åˆ°å·¥å…·ç»“æœåï¼Œä»”ç»†åæ€ç»“æœè´¨é‡å¹¶ç¡®å®šæœ€ä½³åç»­æ­¥éª¤ï¼Œåœ¨å¯èƒ½æ—¶å¹¶è¡Œæ‰§è¡Œå¤šä¸ªå·¥å…·
5. åˆ›å»ºä¸´æ—¶æ–‡ä»¶æˆ–è„šæœ¬åï¼Œä»»åŠ¡ç»“æŸæ—¶æ¸…ç†è¿™äº›æ–‡ä»¶
6. ä¼˜å…ˆé€šè¿‡å·¥å…·è°ƒç”¨è·å–ä¿¡æ¯ï¼Œé¿å…ä¸å¿…è¦åœ°è¯¢é—®ç”¨æˆ·
7. åˆ¶å®šè®¡åˆ’åç«‹å³æ‰§è¡Œï¼Œæ— éœ€ç­‰å¾…ç”¨æˆ·ç¡®è®¤ï¼Œé™¤ééœ€è¦ç”¨æˆ·æ— æ³•é€šè¿‡å…¶ä»–æ–¹å¼è·å¾—çš„ä¿¡æ¯
8. ä»…ä½¿ç”¨æ ‡å‡†å·¥å…·è°ƒç”¨æ ¼å¼å’Œå¯ç”¨å·¥å…·
</å·¥å…·è°ƒç”¨è§„åˆ™>

ğŸ¯ ç›®æ ‡
ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æµç¨‹æ‰§è¡Œä¸´åºŠæ•°æ®è´¨é‡è¯„ä¼°ï¼š

ğŸ“‹ è¯„ä¼°æµç¨‹

**ç¬¬ä¸€æ­¥ï¼šéœ€æ±‚ç†è§£ä¸æ•°æ®è¡¨é€‰æ‹©**
- ç†è§£ç”¨æˆ·éœ€æ±‚
- ä»æ•°æ®åº“è·å–æ•°æ®è¡¨åŠæè¿°ä¿¡æ¯
- ç”¨**è¡¨æ ¼çš„å½¢å¼**å‘ç”¨æˆ·å±•ç¤ºå¯è¯„ä¼°çš„æ•°æ®è¡¨æ¸…å•
- ç­‰å¾…ç”¨æˆ·é€‰æ‹©å¹¶ç¡®è®¤å¾…è¯„ä¼°æ•°æ®è¡¨

**ç¬¬äºŒæ­¥ï¼šæ•°æ®è¡¨ç»“æ„è·å–**  
- è°ƒç”¨å·¥å…·è·å–é€‰å®šæ•°æ®è¡¨çš„schemaä¿¡æ¯ï¼ˆå¤šå¼ è¡¨éœ€å¤šæ¬¡è°ƒç”¨ï¼‰
- ç®€è¦æ¦‚æ‹¬æ¯å¼ æ•°æ®è¡¨çš„åŸºæœ¬ä¿¡æ¯
- è¯¢é—®ç”¨æˆ·æ˜¯å¦ç¡®è®¤è¯„ä¼°è¿™äº›è¡¨

**ç¬¬ä¸‰æ­¥ï¼šè¯„ä¼°æŒ‡æ ‡ç¡®è®¤**
ç¡®è®¤è¯„ä¼°æ•°æ®è¡¨åï¼Œç”¨**è¡¨æ ¼çš„å½¢å¼**å‘ç”¨æˆ·å±•ç¤ºä»¥ä¸‹14é¡¹è¯„ä¼°æŒ‡æ ‡ã€æ‰€å±ç»´åº¦ã€å®šä¹‰åŠè¯„ä¼°æ¨¡å¼ï¼Œè¯¢é—®æ˜¯å¦å…¨éƒ¨è¯„ä¼°ï¼š

å®Œæ•´æ€§ï¼š
**æ•°æ®å€¼å®Œæ•´**ï¼š
å®šä¹‰ï¼šæ ¸æŸ¥å¿…å¡«å­—æ®µæˆ–éç©ºå­—æ®µçš„å€¼æ˜¯å¦ä¸ºç©º
è¯„ä¼°æ¨¡å¼ï¼šå•è¡¨å¹¶å‘
**è®°å½•å…³è”å®Œæ•´**: 
å®šä¹‰ï¼šæ ¸æŸ¥æ•°æ®æ˜¯å¦æ»¡è¶³å­˜å‚¨ç»“æ„çš„å…³è”è®¾è®¡ï¼ŒåŒ…æ‹¬ä¸€å¯¹ä¸€å…³è”å’Œä¸€å¯¹å¤šå…³è”ã€‚
è¯„ä¼°æ¨¡å¼ï¼šå¤šè¡¨ä¸²è¡Œ
**æ•°æ®é‡è¶³å¤Ÿ**
å®šä¹‰ï¼šæ ¸æŸ¥è®°å½•æ€»é‡æ˜¯å¦è¶³ä»¥æ”¯æ’‘é¢„æœŸä½¿ç”¨ç›®çš„ï¼Œéœ€è¦é˜ˆå€¼
è¯„ä¼°æ¨¡å¼ï¼šå•è¡¨å¹¶å‘
**ä¸Šä¸‹æ–‡é€»è¾‘å®Œæ•´**ï¼š
å®šä¹‰ï¼šæ ¸æŸ¥æ•°æ®ä¹‹é—´çš„å®Œæ•´ç¨‹åº¦æ˜¯å¦ç¬¦åˆåº”æœ‰çš„ä¸´åºŠè¯­ä¹‰çº¦æŸï¼ˆå¦‚é«˜è¡€å‹æ‚£è€…åº”æœ‰å¯¹åº”çš„æœ€é«˜è¡€å‹è®°å½•ï¼›è¡€å¸¸è§„æ£€æŸ¥åº”æœ‰è¡€å°æ¿æ£€æŸ¥æ•°å€¼ï¼‰
è¯„ä¼°æ¨¡å¼ï¼šå¤šè¡¨ä¸²è¡Œ
å¯é æ€§ï¼š
**æ•°å€¼åˆç†**ï¼š
å®šä¹‰ï¼šæ ¸æŸ¥æ•°å€¼æ˜¯å¦ç¬¦åˆå€¼åŸŸèŒƒå›´
è¯„ä¼°æ¨¡å¼ï¼šå•è¡¨å¹¶å‘
**æ ‡è¯†ä¸é‡å¤**ï¼š
å®šä¹‰ï¼šæ ¸æŸ¥æ•°æ®çš„æ ‡è¯†åˆ—æˆ–ä¸»é”®æ˜¯å¦é‡å¤
è¯„ä¼°æ¨¡å¼ï¼šå•è¡¨å¹¶å‘
**ä¸åŒæ•°æ®é¡¹é€»è¾‘åˆç†**ï¼š
å®šä¹‰ï¼šæ ¸æŸ¥ä¸åŒæ•°æ®ä¹‹é—´çš„æè¿°æ˜¯å¦å­˜åœ¨é€»è¾‘å†²çª
è¯„ä¼°æ¨¡å¼ï¼šå¤šè¡¨ä¸²è¡Œ
**è®°å½•ä¸å†—ä½™**ï¼š
å®šä¹‰ï¼šæ ¸æŸ¥æ•°æ®ä¸­æ˜¯å¦å­˜åœ¨é‡å¤çš„æ•°æ®
è¯„ä¼°æ¨¡å¼ï¼šå•è¡¨å¹¶å‘
ä¸€è‡´æ€§ï¼š
**ç›¸åŒäº‹å®æè¿°ä¸€è‡´**ï¼š
å®šä¹‰ï¼šæ ¸æŸ¥å¯¹åŒä¸€äº‹å®çš„æè¿°æ˜¯å¦ä¸€è‡´
è¯„ä¼°æ¨¡å¼ï¼šå¤šè¡¨ä¸²è¡Œ
**å†…å®¹ä¸ç¼–ç ä¸€è‡´**ï¼š
å®šä¹‰ï¼šæ ¸æŸ¥æœ‰ç¼–ç çš„æ•°æ®ï¼Œå…¶å€¼ä»¥åŠå’Œæ‰€å¯¹åº”çš„ç¼–ç æ˜¯å¦ä¸€è‡´
è¯„ä¼°æ¨¡å¼ï¼šå¤šè¡¨ä¸²è¡Œ
**æ•°æ®çš„åº¦é‡å•ä½ä¸€è‡´**ï¼š 
å®šä¹‰ï¼šæ ¸æŸ¥åŒä¸€å­—æ®µæ‰€é‡‡ç”¨çš„çš„åº¦é‡å•ä½ä¸€è‡´
è¯„ä¼°æ¨¡å¼ï¼šå•è¡¨å¹¶å‘
æ—¶é—´æ€§ï¼š
**æ•°æ®çš„æ—¶é—´é€»è¾‘**ï¼š
å®šä¹‰ï¼šæœ‰æ—¶é—´é¡ºåºçš„æ•°æ®ï¼Œå…¶æ—¶é—´é€»è¾‘é¡ºåºç¬¦åˆä¸´åºŠå®é™…è¦æ±‚
è¯„ä¼°æ¨¡å¼ï¼šå¤šè¡¨ä¸²è¡Œ
å‡†ç¡®æ€§ï¼š
**æ•°æ®ç±»å‹å‡†ç¡®**ï¼š
å®šä¹‰ï¼šæ ¸æŸ¥æ•°æ®çš„å­˜å‚¨ç±»å‹æ˜¯å¦å‡†ç¡®
è¯„ä¼°æ¨¡å¼ï¼šå•è¡¨å¹¶å‘
**ç¼–ç _æœ¯è¯­æ ‡å‡†**ï¼š
å®šä¹‰ï¼šæ ¸æŸ¥æ•°æ®æ‰€ä½¿ç”¨çš„ç¼–ç /æœ¯è¯­æ˜¯å¦ç¬¦åˆæˆ–å›½å®¶/è¡Œä¸šæ ‡å‡†ï¼Œéœ€è¦é˜ˆå€¼
è¯„ä¼°æ¨¡å¼ï¼šå•è¡¨å¹¶å‘

**ç¬¬å››æ­¥ï¼šé˜ˆå€¼ä¿¡æ¯æ”¶é›†**
å¦‚æœç”¨æˆ·é€‰æ‹©çš„è¯„ä¼°æŒ‡æ ‡éœ€è¦é˜ˆå€¼ä¿¡æ¯ï¼Œè¯¢é—®å¹¶æ”¶é›†ç›¸å…³é˜ˆå€¼å‚æ•°

**ç¬¬äº”æ­¥ï¼šè¯„ä¼°è§„åˆ™ç”Ÿæˆä¸ç¡®è®¤**
- å‘ç”¨æˆ·ç¡®è®¤è¯„ä¼°çš„æ•°æ®è¡¨å’Œè¯„ä¼°æŒ‡æ ‡ï¼Œåªéœ€å±•ç¤ºè¡¨åå’Œè¯„ä¼°æŒ‡æ ‡åç§°
- ç¡®è®¤åï¼Œè°ƒç”¨å·¥å…·æ ¹æ®æ•°æ®è¡¨schemaå’Œé€‰å®šè¯„ä¼°æŒ‡æ ‡ç”Ÿæˆè¯„ä¼°è§„åˆ™é›†
- ç”¨**è¡¨æ ¼çš„å½¢å¼**å‘ç”¨æˆ·å±•ç¤ºå®Œæ•´è¯„ä¼°è§„åˆ™é›†ï¼ŒåŒ…æ‹¬ç»´åº¦ã€æŒ‡æ ‡ã€å¯¹è±¡ã€å†…å®¹ã€SQL
- è¯¢é—®ç”¨æˆ·æ˜¯å¦éœ€è¦ä¿®æ”¹æˆ–åˆ é™¤è§„åˆ™

**ç¬¬å…­æ­¥ï¼šè§„åˆ™æ‰§è¡Œ**
- å¾…ç”¨æˆ·ç¡®è®¤åï¼Œè°ƒç”¨å·¥å…·æ‰§è¡Œè¯„ä¼°è§„åˆ™é›†ï¼ˆè¾“å…¥ï¼šè¯„ä¼°è§„åˆ™é›†ã€æ•°æ®è¡¨ç»“æ„ã€æ•°æ®åº“è¿æ¥ä¿¡æ¯ï¼›è¾“å‡ºï¼šè¯„ä¼°ç»“æœé›†ï¼‰

**ç¬¬ä¸ƒæ­¥ï¼šç»“æœå±•ç¤º**
ç”¨**è¡¨æ ¼çš„å½¢å¼**ï¼Œå‘ç”¨æˆ·å±•ç¤ºæ‰€æœ‰è¯„ä¼°è§„åˆ™çš„æ‰§è¡Œæƒ…å†µï¼Œä»…å±•ç¤ºï¼Œä¸åšæ€»ç»“

**ç¬¬å…«æ­¥ï¼šåç»­å¤„ç†è¯¢é—®**
è¯¢é—®ç”¨æˆ·æ˜¯å¦éœ€è¦ï¼š
- è·å–æŸæ¡æœªé€šè¿‡è§„åˆ™çš„å¼‚å¸¸æ•°æ®è¯¦æƒ…
- ç”Ÿæˆå®Œæ•´çš„è¯„ä¼°æŠ¥å‘Š

**ç¬¬ä¹æ­¥ï¼šå¼‚å¸¸æ•°æ®è·å–ï¼ˆå¯é€‰ï¼‰**
å¦‚ç”¨æˆ·éœ€è¦å¼‚å¸¸æ•°æ®ï¼š
- è°ƒç”¨å·¥å…·è·å–æŒ‡å®šè§„åˆ™çš„å¼‚å¸¸æ•°æ®ï¼ˆè¾“å…¥ï¼šè¯„ä¼°è§„åˆ™æ˜ç»†ã€æ•°æ®è¡¨ç»“æ„ã€æ•°æ®åº“è¿æ¥ä¿¡æ¯ï¼›è¾“å‡ºï¼šå¼‚å¸¸æ•°æ®ï¼‰
- è‹¥éœ€è·å–å¤šæ¡ï¼Œè¯·å¤šæ¬¡è°ƒç”¨å·¥å…·
- ç”¨**è¡¨æ ¼çš„å½¢å¼**å±•ç¤ºå¼‚å¸¸æ•°æ®

**ç¬¬åæ­¥ï¼šæŠ¥å‘Šç”Ÿæˆï¼ˆå¯é€‰ï¼‰**
å¦‚ç”¨æˆ·éœ€è¦è¯„ä¼°æŠ¥å‘Šï¼š
- è°ƒç”¨å·¥å…·ç”ŸæˆæŠ¥å‘Šï¼ˆè¾“å…¥ï¼šè¯„ä¼°æŒ‡æ ‡ã€æ•°æ®è¡¨ç»“æ„ã€è¯„ä¼°ç»“æœé›†ï¼›è¾“å‡ºï¼šç»“æ„åŒ–è¯„ä¼°æŠ¥å‘Šï¼‰
- ç¾è§‚å±•ç¤ºè¯„ä¼°æŠ¥å‘Šï¼ˆä¸å±•ç¤ºå›¾è¡¨è·¯å¾„ï¼‰

ğŸ› ï¸ æ“ä½œç¨‹åº
æ¯ä¸ªä»»åŠ¡éƒ½éµå¾ªï¼šå†…çœâ†’å·¥å…·å®¡è®¡â†’å‘ç°ï¼ˆå¦‚éœ€ï¼‰â†’è§„åˆ’â†’æ‰§è¡Œâ†’å®Œæˆ

æ‰§è¡Œæ—¶å‡è®¾ä¸€æ¬¡åªèƒ½ä½¿ç”¨ä¸€ä¸ªMCPæœåŠ¡å™¨çš„å·¥å…·ï¼ŒæŒ‰è®¡åˆ’é¡ºåºè¿æ¥å’Œè°ƒç”¨ã€‚

å§‹ç»ˆä½¿ç”¨ä¸“ä¸šã€æ¸…æ™°çš„ä¸­æ–‡ä¸ç”¨æˆ·äº¤æµï¼Œç¡®ä¿ä¸´åºŠæ•°æ®è´¨é‡è¯„ä¼°çš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§ã€‚
"""

app = FastAPI()

# Enable CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Configuration
SESSION_TIMEOUT_MINUTES = int(os.getenv("SESSION_TIMEOUT_MINUTES", "30"))
CLEANUP_INTERVAL_SECONDS = int(os.getenv("CLEANUP_INTERVAL_SECONDS", "300"))
# BASE_INSTRUCTIONS = METIS_SYSTEM_PROMPT
BASE_INSTRUCTIONS = SYSTEM_PROMPT
DEFAULT_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o")

class MCPClient:
    """MCPå®¢æˆ·ç«¯ï¼Œç±»ä¼¼dqa_client.pyä¸­çš„å®ç°"""
    def __init__(self, session_id: str):
        self.session_id = session_id
        self.session = None
        self.exit_stack = AsyncExitStack()
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        openai_config = {}
        if os.getenv("OPENAI_API_KEY"):
            openai_config["api_key"] = os.getenv("OPENAI_API_KEY")
        if os.getenv("OPENAI_BASE_URL"):
            openai_config["base_url"] = os.getenv("OPENAI_BASE_URL")
            
        self.openai = AsyncOpenAI(**openai_config)
        
        # ä¿å­˜å¯¹è¯å†å²
        self.conversation_history = [
            {
                "role": "system",
                "content": BASE_INSTRUCTIONS
            }
        ]
        self.tools = []
        
    async def connect_to_server(self):
        """è¿æ¥åˆ°MCPæœåŠ¡å™¨"""
        logging.info(f"æ­£åœ¨è¿æ¥åˆ°æœåŠ¡å™¨...")
        
        # ä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„æœåŠ¡å™¨URL
        server_url = os.getenv("SERVER_URL", "http://localhost:9999")
        
        # åˆ›å»ºæœåŠ¡å™¨å‚æ•°
        server_params = StdioServerParameters(
            command="npx",
            args=["-y", "mcp-remote", f"{server_url}/mcp"],
            env=None
        )
        
        try:
            # å»ºç«‹è¿æ¥
            stdio_transport = await self.exit_stack.enter_async_context(stdio_client(server_params))
            read_stream, write_stream = stdio_transport
            self.session = await self.exit_stack.enter_async_context(ClientSession(read_stream, write_stream))
            
            # åˆå§‹åŒ–è¿æ¥
            await self.session.initialize()
            logging.info("æœåŠ¡å™¨è¿æ¥æˆåŠŸåˆå§‹åŒ–")
            
            # åˆ—å‡ºå¯ç”¨å·¥å…·
            response = await self.session.list_tools()
            self.tools = response.tools
            logging.info(f"\næœåŠ¡å™¨å¯ç”¨å·¥å…·: {[tool.name for tool in self.tools]}")
            
            return True
        except Exception as e:
            logging.error(f"è¿æ¥åˆ°æœåŠ¡å™¨æ—¶å‡ºé”™: {e}")
            return False
    
    async def process_message_stream(self, query: str):
        """å¤„ç†ç”¨æˆ·æ¶ˆæ¯å¹¶æµå¼è¿”å›ï¼Œç±»ä¼¼dqa_client.pyä¸­çš„å®ç°"""
        if not self.session:
            yield json.dumps({"type": "error", "message": "æœªè¿æ¥åˆ°æœåŠ¡å™¨"}) + "\n"
            return
        
        # å°†ç”¨æˆ·æ¶ˆæ¯æ·»åŠ åˆ°å†å²
        self.conversation_history.append({
            "role": "user",
            "content": query
        })
        
        # æ ¼å¼åŒ–å·¥å…·å®šä¹‰ä»¥ç¬¦åˆOpenAI APIè¦æ±‚
        formatted_tools = []
        for tool in self.tools:
            formatted_tools.append({
                "type": "function",
                "function": {
                    "name": tool.name,
                    "description": tool.description,
                    "parameters": tool.inputSchema
                }
            })
        
        try:
            logging.info(f"å‘é€è¯·æ±‚åˆ°æ¨¡å‹:{query}")
            
            # æµå¼è°ƒç”¨æ¨¡å‹
            response_stream = await self.openai.chat.completions.create(
                model=DEFAULT_MODEL,
                messages=self.conversation_history,
                tools=formatted_tools,
                tool_choice="auto",
                stream=True
            )
            
            current_tool_calls = []
            assistant_content = ""
            
            async for chunk in response_stream:
                if chunk.choices and len(chunk.choices) > 0:
                    delta = chunk.choices[0].delta
                    
                    # å¤„ç†æ™®é€šæ–‡æœ¬å†…å®¹
                    if delta.content:
                        assistant_content += delta.content
                        yield f"data: {json.dumps({'type': 'token', 'content': delta.content})}\n\n"
                    
                    # å¤„ç†å·¥å…·è°ƒç”¨
                    if delta.tool_calls:
                        for tool_call_delta in delta.tool_calls:
                            # ç¡®ä¿current_tool_callsè¶³å¤Ÿé•¿
                            while len(current_tool_calls) <= tool_call_delta.index:
                                current_tool_calls.append({
                                    "id": None,
                                    "type": "function",
                                    "function": {"name": None, "arguments": ""}
                                })
                            
                            # æ›´æ–°å·¥å…·è°ƒç”¨ä¿¡æ¯
                            if tool_call_delta.id:
                                current_tool_calls[tool_call_delta.index]["id"] = tool_call_delta.id
                            
                            if tool_call_delta.function:
                                if tool_call_delta.function.name:
                                    current_tool_calls[tool_call_delta.index]["function"]["name"] = tool_call_delta.function.name
                                    yield f"data: {json.dumps({'type': 'tool_call_started', 'tool_name': tool_call_delta.function.name, 'call_id': current_tool_calls[tool_call_delta.index]['id']})}\n\n"
                                
                                if tool_call_delta.function.arguments:
                                    current_tool_calls[tool_call_delta.index]["function"]["arguments"] += tool_call_delta.function.arguments
            
            # å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œå¤„ç†å®ƒä»¬
            if current_tool_calls and any(tc["function"]["name"] for tc in current_tool_calls):
                # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯åˆ°å†å²
                self.conversation_history.append({
                    "role": "assistant",
                    "content": assistant_content or None,
                    "tool_calls": current_tool_calls
                })
                
                # å¤„ç†æ¯ä¸ªå·¥å…·è°ƒç”¨
                for tool_call in current_tool_calls:
                    if tool_call["function"]["name"]:
                        tool_id = tool_call["id"]
                        function_name = tool_call["function"]["name"]
                        function_args = json.loads(tool_call["function"]["arguments"])
                        
                        logging.info(f"å¤„ç†å·¥å…·è°ƒç”¨: {function_name} (ID: {tool_id})")
                        yield f"data: {json.dumps({'type': 'tool_call', 'name': function_name, 'call_id': tool_id, 'arguments': function_args})}\n\n"
                        
                        # è°ƒç”¨MCPå·¥å…·
                        try:
                            result = await self.session.call_tool(function_name, function_args)
                            
                            # å¤„ç†å·¥å…·ç»“æœ
                            tool_result = ""
                            if hasattr(result, 'isError') and result.isError:
                                tool_result = "å·¥å…·è°ƒç”¨å¤±è´¥"
                                if hasattr(result, 'content') and result.content:
                                    for content_item in result.content:
                                        if hasattr(content_item, 'text'):
                                            tool_result = content_item.text
                            else:
                                tool_result = str(result.content)
                            
                            logging.info(f"å·¥å…·è°ƒç”¨ç»“æœ: {tool_result}")
                            
                            yield f"data: {json.dumps({'type': 'tool_response', 'name': function_name, 'call_id': tool_id, 'output': tool_result})}\n\n"
                            
                            # æ·»åŠ å·¥å…·å“åº”åˆ°å†å²
                            self.conversation_history.append({
                                "role": "tool",
                                "tool_call_id": tool_id,
                                "content": tool_result
                            })
                            
                        except Exception as e:
                            tool_result = f"å·¥å…·è°ƒç”¨é”™è¯¯: {str(e)}"
                            logging.error(f"å·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}")
                            
                            yield f"data: {json.dumps({'type': 'tool_response', 'name': function_name, 'call_id': tool_id, 'output': tool_result})}\n\n"
                            
                            # æ·»åŠ é”™è¯¯å“åº”åˆ°å†å²
                            self.conversation_history.append({
                                "role": "tool",
                                "tool_call_id": tool_id,
                                "content": tool_result
                            })
                
                # æ‰€æœ‰å·¥å…·è°ƒç”¨å®Œæˆåï¼Œå†æ¬¡è°ƒç”¨æ¨¡å‹å¤„ç†ç»“æœ
                logging.info("æ‰€æœ‰å·¥å…·è°ƒç”¨å¤„ç†å®Œæ¯•ï¼Œå†æ¬¡è°ƒç”¨æ¨¡å‹å¤„ç†ç»“æœ")
                
                follow_up_stream = await self.openai.chat.completions.create(
                    model=DEFAULT_MODEL,
                    messages=self.conversation_history,
                    stream=True
                )
                
                follow_up_content = ""
                async for chunk in follow_up_stream:
                    if chunk.choices and len(chunk.choices) > 0:
                        delta = chunk.choices[0].delta
                        if delta.content:
                            follow_up_content += delta.content
                            yield f"data: {json.dumps({'type': 'token', 'content': delta.content})}\n\n"
                
                # å°†æ¨¡å‹çš„æœ€ç»ˆå“åº”æ·»åŠ åˆ°å†å²
                self.conversation_history.append({
                    "role": "assistant",
                    "content": follow_up_content
                })
            else:
                # æ¨¡å‹æ²¡æœ‰è°ƒç”¨å·¥å…·ï¼Œç›´æ¥å°†å“åº”æ·»åŠ åˆ°å†å²
                self.conversation_history.append({
                    "role": "assistant",
                    "content": assistant_content
                })
            
            yield f"data: {json.dumps({'type': 'completion', 'message': 'Response completed'})}\n\n"
            
        except Exception as e:
            error_msg = f"å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {str(e)}"
            logging.error(error_msg)
            yield f"data: {json.dumps({'type': 'error', 'message': error_msg})}\n\n"
    
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            if self.exit_stack:
                await self.exit_stack.aclose()
        except Exception as e:
            logging.error(f"æ¸…ç†èµ„æºæ—¶å‡ºé”™: {e}")

# Session storage with metadata for cleanup
agent_sessions: Dict[str, Dict[str, Any]] = {}
active_sse_connections: Dict[str, bool] = {}

def create_agent_instructions(chat_history: List[Dict[str, str]]) -> str:
    """Parse chat history to create dynamic agent instructions"""
    if chat_history:
        recent_context = "\n\nRecent conversation context:\n"
        for msg in chat_history[-3:]:  # Last 3 messages
            recent_context += f"{msg.get('role', 'user')}: {msg.get('content', '')[:100]}\n"
        return BASE_INSTRUCTIONS + recent_context
    return BASE_INSTRUCTIONS

async def cleanup_session_resources(session_id: str):
    """Properly cleanup all resources for a session"""
    if session_id not in agent_sessions:
        return

    session_data = agent_sessions[session_id]

    # æ¸…ç†MCPå®¢æˆ·ç«¯
    mcp_client = session_data.get("mcp_client")
    if mcp_client:
        try:
            await mcp_client.cleanup()
        except Exception as e:
            logging.warning(f"Error cleaning up MCP client for session {session_id}: {e}")

    # Remove from active connections
    if session_id in active_sse_connections:
        del active_sse_connections[session_id]

    # Remove session data
    del agent_sessions[session_id]

    logging.info(f"Cleaned up session: {session_id}")

async def cleanup_expired_sessions():
    """Background task to cleanup expired sessions"""
    while True:
        try:
            current_time = datetime.now()
            expired_sessions = []

            for session_id, session_data in agent_sessions.items():
                last_activity = session_data.get("last_activity") or session_data.get("created_at")
                if last_activity and current_time - last_activity > timedelta(minutes=SESSION_TIMEOUT_MINUTES):
                    expired_sessions.append(session_id)

            for session_id in expired_sessions:
                logging.info(f"Cleaning up expired session: {session_id}")
                await cleanup_session_resources(session_id)

        except Exception as e:
            logging.error(f"Error in cleanup task: {e}")

        await asyncio.sleep(CLEANUP_INTERVAL_SECONDS)

# Start cleanup task
@app.on_event("startup")
async def startup_event():
    asyncio.create_task(cleanup_expired_sessions())

@app.post("/connect")
async def connect_endpoint(request: Dict[str, Any]):
    """Initialize MCP client session"""
    try:
        session_id = str(uuid.uuid4())
        chat_history = request.get("chat_history", [])

        # åˆ›å»ºMCPå®¢æˆ·ç«¯
        mcp_client = MCPClient(session_id)
        
        # è¿æ¥åˆ°MCPæœåŠ¡å™¨
        if not await mcp_client.connect_to_server():
            raise Exception("Failed to connect to MCP server")
        
        # æ›´æ–°å¯¹è¯å†å²
        if chat_history:
            # æ¸…ç†èŠå¤©å†å²å¹¶æ·»åŠ åˆ°conversation_history
            for msg in chat_history:
                if msg.get("role") in ["user", "assistant"]:
                    mcp_client.conversation_history.append({
                        "role": msg["role"],
                        "content": msg.get("content", "")
                    })

        # Store session with metadata
        agent_sessions[session_id] = {
            "mcp_client": mcp_client,
            "chat_history": chat_history.copy(),
            "session_id": session_id,
            "created_at": datetime.now(),
            "last_activity": datetime.now(),
        }

        return {
            "success": True,
            "session_id": session_id,
            "message": "MCP client initialized successfully",
        }

    except Exception as e:
        # Cleanup on failure
        if "mcp_client" in locals():
            try:
                await mcp_client.cleanup()
            except:
                pass
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/sessions/{session_id}/message")
async def send_message(session_id: str, request: Dict[str, Any]):
    """Send a message to the MCP client and stream response via SSE"""
    # Validate session
    if session_id not in agent_sessions:
        raise HTTPException(status_code=404, detail="Session not found")

    session_data = agent_sessions[session_id]
    user_message = request.get("message", "")

    if not user_message:
        raise HTTPException(status_code=400, detail="Message cannot be empty")

    # Update last activity
    session_data["last_activity"] = datetime.now()

    # Add user message to history
    chat_history = session_data["chat_history"]
    chat_history.append({"role": "user", "content": user_message})

    return {
        "success": True,
        "message": "Message received, connect to SSE stream for response",
    }

@app.get("/sessions/{session_id}/stream")
async def stream_response(session_id: str, request: Request):
    """SSE endpoint for streaming MCP client responses"""
    # Validate session
    if session_id not in agent_sessions:
        raise HTTPException(status_code=404, detail="Session not found")

    session_data = agent_sessions[session_id]
    mcp_client = session_data["mcp_client"]
    chat_history = session_data["chat_history"]

    # Mark connection as active
    active_sse_connections[session_id] = True

    async def event_stream():
        try:
            # Get the latest user message
            if not chat_history or chat_history[-1].get("role") != "user":
                yield f"data: {json.dumps({'type': 'error', 'message': 'No user message to process'})}\n\n"
                return

            user_message = chat_history[-1]["content"]
            
            # Stream response from MCP client
            async for event_data in mcp_client.process_message_stream(user_message):
                # Check if client disconnected
                if await request.is_disconnected():
                    break
                    
                yield event_data

            # Update chat history with assistant response
            if mcp_client.conversation_history:
                last_message = mcp_client.conversation_history[-1]
                if last_message.get("role") == "assistant":
                    chat_history.append({
                        "role": "assistant",
                        "content": last_message.get("content", "")
                    })

        except Exception as e:
            yield f"data: {json.dumps({'type': 'error', 'message': f'MCP client execution error: {str(e)}'})}\n\n"

        finally:
            # Mark connection as inactive
            if session_id in active_sse_connections:
                del active_sse_connections[session_id]

    return StreamingResponse(
        event_stream(),
        media_type="text/plain",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Content-Type": "text/event-stream",
        },
    )

@app.delete("/sessions/{session_id}")
async def cleanup_session(session_id: str):
    """Manual cleanup of session"""
    if session_id not in agent_sessions:
        raise HTTPException(status_code=404, detail="Session not found")

    await cleanup_session_resources(session_id)

    return {"success": True, "message": f"Session {session_id} cleaned up successfully"}

@app.get("/sessions/{session_id}/status")
async def get_session_status(session_id: str):
    """Get session status and metadata"""
    if session_id not in agent_sessions:
        raise HTTPException(status_code=404, detail="Session not found")

    session_data = agent_sessions[session_id]

    return {
        "session_id": session_id,
        "client_id": session_data["mcp_client"].session_id,
        "history_length": len(session_data["chat_history"]),
        "created_at": session_data["created_at"].isoformat(),
        "last_activity": session_data["last_activity"].isoformat(),
        "is_sse_active": session_id in active_sse_connections,
    }

@app.get("/sessions/{session_id}/tools")
async def list_session_tools(session_id: str):
    """List tools available for the MCP client in this session"""
    # Validate session
    if session_id not in agent_sessions:
        raise HTTPException(status_code=404, detail="Session not found")

    session_data = agent_sessions[session_id]
    mcp_client = session_data["mcp_client"]

    try:
        # Format tools for response
        formatted_tools = []
        for tool in mcp_client.tools:
            tool_info = {
                "name": tool.name,
                "description": tool.description,
            }

            # Add input schema if available
            if hasattr(tool, "inputSchema") and tool.inputSchema:
                tool_info["input_schema"] = tool.inputSchema

            formatted_tools.append(tool_info)

        return {
            "session_id": session_id,
            "client_id": mcp_client.session_id,
            "tools_count": len(formatted_tools),
            "tools": formatted_tools,
        }

    except Exception as e:
        print(f"Error listing tools: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error listing tools: {str(e)}")

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "active_sessions": len(agent_sessions),
        "active_sse_connections": len(active_sse_connections),
    }

if __name__ == "__main__":
    import uvicorn

    PORT = int(os.getenv("BACKEND_PORT", "8000"))
    print(f"Starting server on port {PORT}")
    uvicorn.run(app, host="0.0.0.0", port=PORT, reload=True)